{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMiLPUPi8rY0XojPuXgTCNf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GomathyDhanya/SnakeAgent/blob/main/Snake.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install stable-baselines3[extra] gymnasium shimmy"
      ],
      "metadata": {
        "id": "Z-GslYTO2pUZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import gymnasium as gym\n",
        "from gymnasium import spaces\n",
        "import numpy as np\n",
        "import random\n",
        "from stable_baselines3 import PPO\n",
        "from IPython.display import clear_output\n",
        "\n",
        "class SnakeLidarEnv(gym.Env):\n",
        "    def __init__(self):\n",
        "        super(SnakeLidarEnv, self).__init__()\n",
        "\n",
        "        self.action_space = spaces.Discrete(3)\n",
        "\n",
        "        self.observation_space = spaces.Box(low=0, high=1, shape=(20,), dtype=np.float32)\n",
        "\n",
        "        self.w = 10\n",
        "        self.h = 10\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self, seed=None, options=None):\n",
        "        super().reset(seed=seed)\n",
        "        self.direction = 0\n",
        "        self.head = np.array([self.w // 2, self.h // 2])\n",
        "        self.snake = [self.head.copy(), self.head - [1, 0], self.head - [2, 0]]\n",
        "        self.score = 0\n",
        "        self.food = None\n",
        "        self._place_food()\n",
        "        self.frame_iteration = 0\n",
        "        return self._get_state(), {}\n",
        "\n",
        "    def _place_food(self):\n",
        "        while True:\n",
        "            x, y = random.randint(0, self.w - 1), random.randint(0, self.h - 1)\n",
        "            self.food = np.array([x, y])\n",
        "            if not any(np.array_equal(self.food, s) for s in self.snake): break\n",
        "\n",
        "    def step(self, action):\n",
        "        self.frame_iteration += 1\n",
        "\n",
        "        clock_wise = [0, 1, 2, 3]\n",
        "        idx = clock_wise.index(self.direction)\n",
        "        if action == 1: self.direction = clock_wise[(idx + 1) % 4]\n",
        "        elif action == 2: self.direction = clock_wise[(idx - 1) % 4]\n",
        "\n",
        "        move_map = {0: [1, 0], 1: [0, 1], 2: [-1, 0], 3: [0, -1]}\n",
        "        self.head = self.head + np.array(move_map[self.direction])\n",
        "\n",
        "        terminated = False\n",
        "        reward = 0\n",
        "\n",
        "        if (self.head[0] < 0 or self.head[0] >= self.w or\n",
        "            self.head[1] < 0 or self.head[1] >= self.h or\n",
        "            any(np.array_equal(self.head, s) for s in self.snake[1:])):\n",
        "            terminated = True\n",
        "            reward = -10\n",
        "\n",
        "        elif self.frame_iteration > 100 * len(self.snake):\n",
        "            terminated = True\n",
        "            reward = -10\n",
        "\n",
        "        if terminated:\n",
        "            return self._get_state(), reward, terminated, False, {}\n",
        "\n",
        "        self.snake.insert(0, self.head.copy())\n",
        "        if np.array_equal(self.head, self.food):\n",
        "            self.score += 1\n",
        "            reward = 10\n",
        "            self._place_food()\n",
        "        else:\n",
        "            self.snake.pop()\n",
        "\n",
        "        return self._get_state(), reward, terminated, False, {}\n",
        "\n",
        "    def _get_state(self):\n",
        "\n",
        "        directions = [\n",
        "            [1, 0], [1, 1], [0, 1], [-1, 1],\n",
        "            [-1, 0], [-1, -1], [0, -1], [1, -1]\n",
        "        ]\n",
        "\n",
        "        vision_dist = []\n",
        "        vision_food = []\n",
        "\n",
        "        for d in directions:\n",
        "            dist = 0\n",
        "            found_food = 0\n",
        "            curr = self.head.copy()\n",
        "\n",
        "            while True:\n",
        "                curr = curr + d\n",
        "                dist += 1\n",
        "\n",
        "                if (curr[0] < 0 or curr[0] >= self.w or\n",
        "                    curr[1] < 0 or curr[1] >= self.h or\n",
        "                    any(np.array_equal(curr, s) for s in self.snake)):\n",
        "                    break\n",
        "\n",
        "                if np.array_equal(curr, self.food):\n",
        "                    found_food = 1\n",
        "\n",
        "            vision_dist.append(1.0 / dist)\n",
        "            vision_food.append(found_food)\n",
        "\n",
        "        dir_one_hot = [0, 0, 0, 0]\n",
        "        dir_one_hot[self.direction] = 1.0\n",
        "\n",
        "        state = np.concatenate([vision_dist, vision_food, dir_one_hot])\n",
        "        return np.array(state, dtype=np.float32)\n",
        "\n",
        "    def render_ascii(self):\n",
        "        board = [['.' for _ in range(self.w)] for _ in range(self.h)]\n",
        "        board[self.food[1]][self.food[0]] = 'F'\n",
        "        for i, pt in enumerate(self.snake):\n",
        "            char = 'H' if i == 0 else 'o'\n",
        "            if 0 <= pt[1] < self.h and 0 <= pt[0] < self.w:\n",
        "                board[pt[1]][pt[0]] = char\n",
        "        print(f\"Score: {self.score}\")\n",
        "        print(\"+\" + \"-\" * self.w + \"+\")\n",
        "        for row in board:\n",
        "            print(\"|\" + \"\".join(row) + \"|\")\n",
        "        print(\"+\" + \"-\" * self.w + \"+\")\n",
        "\n",
        "env = SnakeLidarEnv()\n",
        "model = PPO(\"MlpPolicy\", env, verbose=1)\n",
        "model.learn(total_timesteps=200000)\n",
        "\n",
        "\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=10)\n",
        "print(f\"New Mean Reward: {mean_reward:.2f} +/- {std_reward:.2f}\")\n"
      ],
      "metadata": {
        "id": "P8HdmVsywbeL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "obs, _ = env.reset()\n",
        "done = False\n",
        "while not done:\n",
        "    action, _ = model.predict(obs)\n",
        "    obs, reward, done, _, _ = env.step(action)\n",
        "    clear_output(wait=True)\n",
        "    env.render_ascii()"
      ],
      "metadata": {
        "id": "3ZeJIoSv90d3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ct_zJ4Cy3XZH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}